{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bvyCHreeQAj"
      },
      "source": [
        "# Meeting Minutes Generator From Audio File\n",
        "\n",
        "**Author:** [Pouria Ebrahimnezhad]  \n",
        "**Date:** [14-03-2025]  \n",
        "**Description:** This Jupyter Notebook uses a Hugging Face audio model to transcribe city council meeting audio recordings\n",
        "and generate structured meeting minutes in Markdown format.\n",
        "\n",
        "## Installation\n",
        "Ensure dependencies are installed:\n",
        "```bash\n",
        "pip install -q requests torch bitsandbytes transformers sentencepiece accelerate openai httpx==0.27.2\n",
        "```\n",
        "\n",
        "## Usage\n",
        "1. **Specify the audio file path** in the `AUDIO_FILE` variable.\n",
        "2. **Run the notebook** to process the audio and generate minutes.\n",
        "3. **Review and edit the Markdown output** as needed.\n",
        "4. **Save or share the meeting minutes.**\n",
        "\n",
        "## Example Markdown Output\n",
        "\n",
        "# City Council Meeting - [Date]\n",
        "\n",
        "## Attendees\n",
        "- [List of Attendees]\n",
        "\n",
        "## Agenda\n",
        "1. [Agenda Item 1]\n",
        "2. [Agenda Item 2]\n",
        "\n",
        "## Key Decisions\n",
        "- [Decision 1]\n",
        "- [Decision 2]\n",
        "\n",
        "## Action Items\n",
        "- [Task 1]\n",
        "- [Task 2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 3913,
          "status": "ok",
          "timestamp": 1741935240463,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "f2vvgnFpHpID"
      },
      "outputs": [],
      "source": [
        "#!pip install -q requests torch bitsandbytes transformers sentencepiece accelerate openai httpx==0.27.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1741936770055,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "FW8nl3XRFrz0"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n",
        "from google.colab import drive\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig, AutoModelForSpeechSeq2Seq, AutoProcessor\n",
        "import torch\n",
        "import re\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 13,
          "status": "ok",
          "timestamp": 1741935241658,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "q3D1_T0uG_Qh"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "\n",
        "AUDIO_MODEL = \"whisper-1\"\n",
        "LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 33449,
          "status": "ok",
          "timestamp": 1741935231003,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "Es9GkQ0FGCMt",
        "outputId": "eed46b20-752a-4119-96f5-37ca09689351"
      },
      "outputs": [],
      "source": [
        "# Connect to Colab to Google Drive and locate the Audio File\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "audio_filename = \"/content/drive/MyDrive/llms/Seattle-council-extract.mp3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 5143,
          "status": "ok",
          "timestamp": 1741935266761,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "xYW8kQYtF-3L"
      },
      "outputs": [],
      "source": [
        "# Sign in to HuggingFace Hub\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 3664,
          "status": "ok",
          "timestamp": 1741935342918,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "qP6OB2OeGC2C"
      },
      "outputs": [],
      "source": [
        "# Sign in to OpenAI using Secrets in Colab\n",
        "\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "openai = OpenAI(api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 26925,
          "status": "ok",
          "timestamp": 1741935396024,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "GMShdVGlGGr4",
        "outputId": "b18163d0-7138-4803-9712-c481876ea612"
      },
      "outputs": [],
      "source": [
        "# Use the Whisper OpenAI model to convert the Audio to Text\n",
        "\n",
        "audio_file = open(audio_filename, \"rb\")\n",
        "transcription = openai.audio.transcriptions.create(model=AUDIO_MODEL, file=audio_file, response_format=\"text\")\n",
        "print(transcription)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 18,
          "status": "ok",
          "timestamp": 1741935433235,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "piEMmcSfMH-O"
      },
      "outputs": [],
      "source": [
        "system_message = \"You are an assistant that produces minutes of meetings from transcripts, with summary, key discussion points, takeaways and action items with owners, in markdown.\"\n",
        "user_prompt = f\"Below is an extract transcript of a Seattle council meeting. Please write minutes in markdown, including a summary with attendees, location and date; discussion points; takeaways; and action items with owners.\\n{transcription}\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"content\": user_prompt}\n",
        "  ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 15,
          "status": "ok",
          "timestamp": 1741935576051,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "UcRKUgcxMew6"
      },
      "outputs": [],
      "source": [
        "# define the contization to reduce the memory impact of the models\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3da04571b67b4d2caab68cf3256ec270",
            "101e5b667a754e22ab283fc13e34f2b2",
            "190e841c0f0342c2b82b5429d7b51d96",
            "b5798f364031492184a2d5c117221375",
            "4bcf5d6b51b842d3a2f95598f1d6715c",
            "5de44b3c95bb4318a5b4e2e576fbf763",
            "f4a7b2da233f4620b7a5c94c12cdecde",
            "1c2151e90318493fb12dd224321eeef0",
            "b71b0deaa9b244cfa1611d0c7a2a1a52",
            "4d9abd55971c4d899cddf59e109d7dd0",
            "aa53b7b728294c60a8fe8f6f5832a677"
          ]
        },
        "executionInfo": {
          "elapsed": 146179,
          "status": "ok",
          "timestamp": 1741936268018,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "6CujZRAgMimy",
        "outputId": "091bdfec-d75c-460a-db05-48913f125e83"
      },
      "outputs": [],
      "source": [
        "# cerate a tokenizer for the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(LLAMA)\n",
        "# setting the padding\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "# pass in the message and the entire transcript and use GPU\n",
        "inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
        "# use streaming\n",
        "streamer = TextStreamer(tokenizer)\n",
        "# create the model passing the model and, GPU utilization and the quantization config from above\n",
        "model = AutoModelForCausalLM.from_pretrained(LLAMA, device_map=\"auto\", quantization_config=quant_config)\n",
        "\n",
        "\n",
        "outputs = model.generate(inputs, max_new_tokens=2000, streamer=streamer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "elapsed": 75,
          "status": "ok",
          "timestamp": 1741936821775,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "102tdU_3Peam",
        "outputId": "c9ca35eb-5b22-4f79-8e9f-7e6f912da5f4"
      },
      "outputs": [],
      "source": [
        "response = tokenizer.decode(outputs[0])\n",
        "display(Markdown(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU3uAEyU3a-o"
      },
      "source": [
        "## Alternative implementation\n",
        "\n",
        "This variation uses an open-source model to transcribe the meeting Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 11144,
          "status": "ok",
          "timestamp": 1741936556934,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "HdQnWEzW3lzP",
        "outputId": "2f431dc2-f11b-4a17-dbde-80f178d7dcf2"
      },
      "outputs": [],
      "source": [
        "AUDIO_MODEL = \"openai/whisper-medium\"\n",
        "speech_model = AutoModelForSpeechSeq2Seq.from_pretrained(AUDIO_MODEL, torch_dtype=torch.float16, low_cpu_mem_usage=True, use_safetensors=True)\n",
        "speech_model.to('cuda')\n",
        "processor = AutoProcessor.from_pretrained(AUDIO_MODEL)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=speech_model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    torch_dtype=torch.float16,\n",
        "    device='cuda',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 75445,
          "status": "ok",
          "timestamp": 1741936676719,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "nrQjKtD53omJ",
        "outputId": "ae5b9645-d318-40ec-b108-bb9a0154db01"
      },
      "outputs": [],
      "source": [
        "# Use the Whisper OpenAI model to convert the Audio to Text\n",
        "result = pipe(audio_filename, return_timestamps=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 27,
          "status": "ok",
          "timestamp": 1741936884305,
          "user": {
            "displayName": "Pouria Ebram",
            "userId": "07641656286736993990"
          },
          "user_tz": -660
        },
        "id": "G_XSljOY3tDf",
        "outputId": "bee7821b-a8d4-40d1-f6eb-d51dff330d34"
      },
      "outputs": [],
      "source": [
        "transcription = result[\"text\"]\n",
        "print(transcription)"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 4
}